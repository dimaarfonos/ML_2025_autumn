{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJvcx5DfhHnf"
   },
   "source": [
    "# Домашнее задание  - предобработка признаков, pandas\n",
    "\n",
    "\n",
    "### О задании\n",
    "\n",
    "Практическое задание 2 посвящено изучению основных библиотек для анализа данных, а также линейных моделей и методов их обучения. Вы научитесь:\n",
    " * применять библиотеки NumPy и Pandas для осуществления желаемых преобразований;\n",
    " * подготавливать данные для обучения линейных моделей;\n",
    " * обучать линейную, Lasso и Ridge-регрессии при помощи модуля scikit-learn;\n",
    " * реализовывать обычный и стохастический градиентные спуски;\n",
    " * обучать линейную регрессию для произвольного функционала качества.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов. Кроме того, некоторые из заданий являются опциональными (необязательными), однако за их выполнение можно получить дополнительные баллы, которые позднее будут учитываться при проставлении оценок автоматом по курсу.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце Вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания получившийся файл \\*.ipynb с решением необходимо выложить в свой репозиторий github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpmfnsDohHnh"
   },
   "source": [
    "## \n",
    "\n",
    "Библиотеки для анализа данных\n",
    "\n",
    "### NumPy\n",
    "\n",
    "Во всех заданиях данного раздела запрещено использовать циклы  и list comprehensions. Под вектором и матрицей в данных заданиях понимается одномерный и двумерный numpy.array соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kfll_OX7hHni"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMzqQsW4hHni"
   },
   "source": [
    "**1. (0.2 балла)** Реализуйте функцию, возвращающую максимальный элемент в векторе x среди элементов, перед которыми стоит нулевой. Для x = np.array([6, 2, 0, 3, 0, 0, 5, 7, 0]) ответом является 5. Если нулевых элементов нет, функция должна возвращать None.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXaK8SKuhHnj",
    "outputId": "2ea68c4b-54e4-461a-8a01-3e1045a6fd50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тест 1: 5\n",
      "Тест 2: None\n"
     ]
    }
   ],
   "source": [
    "def max_element(arr):\n",
    "    # индексы нулевых элементов\n",
    "    zero_indices = np.where(arr == 0)[0]\n",
    "    # Индексы после нулевых\n",
    "    next_indices = zero_indices + 1\n",
    "    # Отфильтровываем индексы\n",
    "    valid_indices = next_indices[(next_indices < len(arr)) & (next_indices >= 0)]\n",
    "\n",
    "    if len(valid_indices) == 0:\n",
    "        return None\n",
    "\n",
    "    # Возвращаем максимальный элемент среди следующих после нулевых\n",
    "    return np.max(arr[valid_indices])\n",
    "\n",
    "# Тест\n",
    "x = np.array([6, 2, 0, 3, 0, 0, 5, 7, 0])\n",
    "print(f\"Тест 1: {max_element(x)}\")\n",
    "\n",
    "x2 = np.array([1, 2, 3])\n",
    "print(f\"Тест 2: {max_element(x2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaXVuRA0hHnj"
   },
   "source": [
    "**2. (0.2 балла)** Реализуйте функцию, принимающую на вход матрицу и некоторое число и возвращающую ближайший к числу элемент матрицы. Например: для X = np.arange(0,10).reshape((2, 5)) и v = 3.6 ответом будет 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HVjzwg_XhHnj",
    "outputId": "17a8a5ba-c8e4-4477-90be-24516fc3af2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ближайший к 3.6: 4\n"
     ]
    }
   ],
   "source": [
    "def nearest_value(X, v):\n",
    "    # Находим абсолютную разницу и возвращаем элемент с минимальной разницей\n",
    "    return X.flat[np.argmin(np.abs(X - v))]\n",
    "\n",
    "# Тест\n",
    "X = np.arange(0, 10).reshape((2, 5))\n",
    "v = 3.6\n",
    "print(f\"Ближайший к {v}: {nearest_value(X, v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7ljfxEJhHnj"
   },
   "source": [
    "**3. (0.2 балла)** Реализуйте функцию scale(X), которая принимает на вход матрицу и масштабирует каждый ее столбец (вычитает выборочное среднее и делит на стандартное отклонение). Убедитесь, что в функции не будет происходить деления на ноль. Протестируйте на случайной матрице (для её генерации можно использовать, например, функцию [numpy.random.randint](http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randint.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6BbawR5qhHnj",
    "outputId": "1cf621f6-7bcb-428b-8e33-4a14e03cb491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходная матрица:\n",
      "[[51 92 14]\n",
      " [71 60 20]\n",
      " [82 86 74]\n",
      " [74 87 99]\n",
      " [23  2 21]]\n",
      "\n",
      "Масштабированная матрица:\n",
      "[[-0.43361508  0.79149842 -0.9185736 ]\n",
      " [ 0.5090264  -0.16068013 -0.74416089]\n",
      " [ 1.02747921  0.61296494  0.82555349]\n",
      " [ 0.65042262  0.64272052  1.55227311]\n",
      " [-1.75331314 -1.88650376 -0.71509211]]\n",
      "\n",
      "Проверка: среднее по столбцам ~ 0\n",
      "[-8.88178420e-17 -1.33226763e-16 -4.44089210e-17]\n",
      "Проверка: std по столбцам ~ 1\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "def scale(X):\n",
    "    # среднее по столбцам\n",
    "    X_scaled = X - np.mean(X, axis=0)\n",
    "    # стандартное отклонение по столбцам\n",
    "    std = np.std(X, axis=0)\n",
    "    # Заменяем нулевые стандартные отклонения на 1, чтобы избежать деления на ноль\n",
    "    std[std == 0] = 1\n",
    "    return X_scaled / std\n",
    "\n",
    "# Тест\n",
    "np.random.seed(42)\n",
    "X_test = np.random.randint(0, 100, size=(5, 3))\n",
    "print(\"Исходная матрица:\")\n",
    "print(X_test)\n",
    "print(\"\\nМасштабированная матрица:\")\n",
    "print(scale(X_test))\n",
    "print(\"\\nПроверка: среднее по столбцам ~ 0\")\n",
    "print(np.mean(scale(X_test), axis=0))\n",
    "print(\"Проверка: std по столбцам ~ 1\")\n",
    "print(np.std(scale(X_test), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9A8rUOIhHnj"
   },
   "source": [
    "**4. (0.2 балла)** Реализуйте функцию, которая для заданной матрицы находит:\n",
    " - определитель\n",
    " - след\n",
    " - наименьший и наибольший элементы\n",
    " - норму Фробениуса\n",
    " - собственные числа\n",
    " - обратную матрицу\n",
    "\n",
    "Для тестирования сгенерируйте матрицу с элементами из нормального распределения $\\mathcal{N}$(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MANU8lRGhHnj",
    "outputId": "3cecf861-9366-4082-b8a9-d0765b630e2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тестовая матрица:\n",
      "[[10.49671415  9.8617357  10.64768854]\n",
      " [11.52302986  9.76584663  9.76586304]\n",
      " [11.57921282 10.76743473  9.53052561]]\n",
      "\n",
      "Статистики:\n",
      "determinant: 22.4038\n",
      "trace: 29.7931\n",
      "min_element: 9.5305\n",
      "max_element: 11.5792\n",
      "frobenius_norm: 31.3876\n",
      "eigenvalues: [31.30028766+0.j        -0.75360063+0.3845192j -0.75360063-0.3845192j]\n",
      "inverse: \\n[[-0.53917888  0.9222003  -0.34259108]\n",
      " [ 0.14553242 -1.03788982  0.9009268 ]\n",
      " [ 0.49066089  0.05215424 -0.49669197]]\n"
     ]
    }
   ],
   "source": [
    "def get_stats(X):\n",
    "    stats = {}\n",
    "\n",
    "    # Определитель\n",
    "    if X.shape[0] == X.shape[1]:\n",
    "        stats['determinant'] = np.linalg.det(X)\n",
    "    else:\n",
    "        stats['determinant'] = \"Не определен для неквадратной матрицы\"\n",
    "\n",
    "    # сумма диагональных элементов\n",
    "    stats['trace'] = np.trace(X)\n",
    "\n",
    "    # Минимальный и максимальный элементы\n",
    "    stats['min_element'] = np.min(X)\n",
    "    stats['max_element'] = np.max(X)\n",
    "\n",
    "    # Норма Фробениуса\n",
    "    stats['frobenius_norm'] = np.linalg.norm(X, 'fro')\n",
    "\n",
    "    # Собственные числа\n",
    "    if X.shape[0] == X.shape[1]:\n",
    "        stats['eigenvalues'] = np.linalg.eigvals(X)\n",
    "    else:\n",
    "        stats['eigenvalues'] = \"Не определены для неквадратной матрицы\"\n",
    "\n",
    "    # Обратная матрица\n",
    "    if X.shape[0] == X.shape[1] and np.linalg.det(X) != 0:\n",
    "        stats['inverse'] = np.linalg.inv(X)\n",
    "    else:\n",
    "        stats['inverse'] = \"Не определена\"\n",
    "\n",
    "    return stats\n",
    "\n",
    "# Тест\n",
    "np.random.seed(42)\n",
    "X_test = np.random.normal(10, 1, size=(3, 3))\n",
    "print(\"Тестовая матрица:\")\n",
    "print(X_test)\n",
    "print(\"\\nСтатистики:\")\n",
    "stats = get_stats(X_test)\n",
    "for key, value in stats.items():\n",
    "    if key in ['eigenvalues', 'inverse'] and isinstance(value, str):\n",
    "        print(f\"{key}: {value}\")\n",
    "    elif key == 'eigenvalues':\n",
    "        print(f\"{key}: {value}\")\n",
    "    elif key == 'inverse':\n",
    "        print(f\"{key}: \\\\n{value}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ziwF0W_5hHnk"
   },
   "source": [
    "**5. (0.2 балла)** Повторите 100 раз следующий эксперимент: сгенерируйте две матрицы размера 10×10 из стандартного нормального распределения, перемножьте их (как матрицы) и найдите максимальный элемент. Какое среднее значение по экспериментам у максимальных элементов? 95-процентная квантиль?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3kHEct7EhHnk",
    "outputId": "e8e7287c-a807-45a6-fdf3-f6c9779d4c4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение максимальных элементов: 8.2857\n",
      "95-процентная квантиль: 11.6625\n",
      "Минимальное значение: 4.6062\n",
      "Максимальное значение: 12.8207\n"
     ]
    }
   ],
   "source": [
    "max_elements = []\n",
    "\n",
    "for exp_num in range(100):\n",
    "    A = np.random.randn(10, 10)\n",
    "    B = np.random.randn(10, 10)\n",
    "\n",
    "    \n",
    "    C = np.dot(A, B)\n",
    "\n",
    "    # максимальный элемент\n",
    "    max_elem = np.max(C)\n",
    "    max_elements.append(max_elem)\n",
    "\n",
    "\n",
    "max_elements = np.array(max_elements)\n",
    "\n",
    "mean_max = np.mean(max_elements)\n",
    "percentile_95 = np.percentile(max_elements, 95)\n",
    "\n",
    "print(f\"Среднее значение максимальных элементов: {mean_max:.4f}\")\n",
    "print(f\"95-процентная квантиль: {percentile_95:.4f}\")\n",
    "print(f\"Минимальное значение: {np.min(max_elements):.4f}\")\n",
    "print(f\"Максимальное значение: {np.max(max_elements):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J56cAplnhHnk"
   },
   "source": [
    "### Pandas\n",
    "\n",
    "![](https://metrouk2.files.wordpress.com/2015/10/panda.jpg)\n",
    "\n",
    "#### Ответьте на вопросы о данных по авиарейсам в США за январь-апрель 2008 года.\n",
    "\n",
    "Данные находятся в приложенном файле `2008.csv`. Их [описание](http://stat-computing.org/dataexpo/2009/the-data.html) приведено ниже:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4yJbue-hHnk"
   },
   "source": [
    "Airline on-time performance\n",
    "\n",
    "Have you ever been stuck in an airport because your flight was delayed or cancelled and wondered if you could have predicted it if you'd had more data? This is your chance to find out.\n",
    "\n",
    "The data\n",
    "The data set is available for download here.\n",
    "The data consists of flight arrival and departure details for all commercial flights within the USA, from October 1987 to April 2008. This is a large dataset: there are nearly 120 million records in total, and takes up 1.6 gigabytes of space compressed and 12 gigabytes when uncompressed.\n",
    "\n",
    "Understanding and preparing the data\n",
    "In order to answer above questions, we are going to analyze the provided dataset, containing up to 1936758 ### different internal flights in the US for 2008 and their causes for delay, diversion and cancellation\n",
    "\n",
    "The data comes from the U.S. Department of Transportation’s (DOT) Bureau of Transportation Statistics (BTS). Meta data explanations\n",
    "\n",
    "This dataset is composed by the following variables:\n",
    "\n",
    "**Year** 2008 **Month** 1-12 **DayofMonth** 1-31 **DayOfWeek** 1 (Monday) - 7 (Sunday)  \n",
    "**DepTime** actual departure time (local, hhmm)  \n",
    "**CRSDepTime** scheduled departure time (local, hhmm)  \n",
    "**ArrTime** actual arrival time (local, hhmm)  \n",
    "**CRSArrTime** scheduled arrival time (local, hhmm)  \n",
    "**UniqueCarrier** unique carrier code  \n",
    "**FlightNum** flight number  \n",
    "**TailNum** plane tail number: aircraft registration, unique aircraft identifier  \n",
    "**ActualElapsedTime** in minutes  \n",
    "**CRSElapsedTime** in minutes  \n",
    "**AirTime** in minutes  \n",
    "**ArrDelay** arrival delay, in minutes: A flight is counted as “on time” if it operated less than 15 minutes later the scheduled time shown in the carriers’ Computerized Reservations Systems (CRS).  \n",
    "**DepDelay** departure delay, in minutes  \n",
    "**Origin** origin IATA airport code  \n",
    "**Dest** destination IATA airport code  \n",
    "**Distance** in miles  \n",
    "**TaxiIn** taxi in time, in minutes  \n",
    "**TaxiOut** taxi out time in minutes  \n",
    "**Cancelled** *was the flight cancelled  \n",
    "**CancellationCode** reason for cancellation (A = carrier, B = weather, C = NAS, D = security)  \n",
    "**Diverted** 1 = yes, 0 = no  \n",
    "**CarrierDelay** in minutes: Carrier delay is within the control of the air carrier. Examples of occurrences that may determine carrier delay are: aircraft cleaning, aircraft damage, awaiting the arrival of connecting passengers or crew, baggage, bird strike, cargo loading, catering, computer, outage-carrier equipment, crew legality (pilot or attendant rest), damage by hazardous goods, engineering inspection, fueling, handling disabled passengers, late crew, lavatory servicing, maintenance, oversales, potable water servicing, removal of unruly passenger, slow boarding or seating, stowing carry-on baggage, weight and balance delays.  \n",
    "**WeatherDelay** in minutes: Weather delay is caused by extreme or hazardous weather conditions that are forecasted or manifest themselves on point of departure, enroute, or on point of arrival.  \n",
    "**NASDelay** in minutes: Delay that is within the control of the National Airspace System (NAS) may include: non-extreme weather conditions, airport operations, heavy traffic volume, air traffic control, etc.  \n",
    "**SecurityDelay** in minutes: Security delay is caused by evacuation of a terminal or concourse, re-boarding of aircraft because of security breach, inoperative screening equipment and/or long lines in excess of 29 minutes at screening areas.  \n",
    "**LateAircraftDelay** in minutes: Arrival delay at an airport due to the late arrival of the same aircraft at a previous airport. The ripple effect of an earlier delay at downstream airports is referred to as delay propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIV80KkbhHnk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gEudeXChHnl"
   },
   "source": [
    "**6. (0.3 балла)** Какая из причин отмены рейса (`CancellationCode`) была самой частой? (расшифровки кодов можно найти в описании данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cH4EDAurhHnl",
    "outputId": "b6109de0-0b22-46d0-b0e6-275b98dd15a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение причин отмены рейсов:\n",
      "CancellationCode\n",
      "A    563\n",
      "B    549\n",
      "C    299\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Самая частая причина отмены рейса: A\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "df = pd.read_csv('2008.csv')\n",
    "\n",
    "# Анализ причин отмены рейсов\n",
    "cancellation_counts = df['CancellationCode'].value_counts()\n",
    "print(\"Распределение причин отмены рейсов:\")\n",
    "print(cancellation_counts)\n",
    "\n",
    "# Самая частая причина\n",
    "most_common_cancellation = cancellation_counts.index[0]\n",
    "print(f\"\\nСамая частая причина отмены рейса: {most_common_cancellation}\")\n",
    "\n",
    "# Расшифровка кодов (из описания данных):\n",
    "# A - Carrier (авиакомпания)\n",
    "# B - Weather (погода)\n",
    "# C - National Air System (национальная воздушная система)\n",
    "# D - Security (безопасность)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4R1hLpyhHnl"
   },
   "source": [
    "**7. (0.3 балла)** Найдите среднее, минимальное и максимальное расстояние, пройденное самолетом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "5Ymt5uEnhHnl",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "e08564ca-1d75-49b2-b112-4de48611915a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Статистика по пройденному расстоянию:\n",
      "Среднее расстояние: 724.51 миль\n",
      "Минимальное расстояние: 31 миль\n",
      "Максимальное расстояние: 4962 миль\n",
      "\n",
      "Рейсы с минимальным расстоянием (31 миль):\n",
      "       Year  Month  DayofMonth UniqueCarrier  FlightNum Origin Dest  Distance\n",
      "1116   2008     12          30            AS         65    WRG  PSG        31\n",
      "6958   2008     12          26            AS         65    WRG  PSG        31\n",
      "17349  2008      8          18            AS         64    PSG  WRG        31\n",
      "27534  2008      3          11            AS         64    PSG  WRG        31\n",
      "46082  2008      8           9            AS         65    WRG  PSG        31\n",
      "48112  2008      2          28            AS         64    PSG  WRG        31\n",
      "\n",
      "Все рейсы AS65 WRG-PSG:\n",
      "       Year  Month  DayofMonth  Distance\n",
      "46082  2008      8           9        31\n",
      "6958   2008     12          26        31\n",
      "1116   2008     12          30        31\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Статистика по расстояниям\n",
    "mean_distance = df['Distance'].mean()\n",
    "min_distance = df['Distance'].min()\n",
    "max_distance = df['Distance'].max()\n",
    "\n",
    "print(f\"Статистика по пройденному расстоянию:\")\n",
    "print(f\"Среднее расстояние: {mean_distance:.2f} миль\")\n",
    "print(f\"Минимальное расстояние: {min_distance} миль\")\n",
    "print(f\"Максимальное расстояние: {max_distance} миль\")\n",
    "\n",
    "# Анализ \n",
    "min_distance_flights = df[df['Distance'] == min_distance]\n",
    "print(f\"\\nРейсы с минимальным расстоянием ({min_distance} миль):\")\n",
    "print(min_distance_flights[['Year', 'Month', 'DayofMonth', 'UniqueCarrier', 'FlightNum', 'Origin', 'Dest', 'Distance']])\n",
    "\n",
    "\n",
    "if not min_distance_flights.empty:\n",
    "    carrier = min_distance_flights['UniqueCarrier'].iloc[0]\n",
    "    flight_num = min_distance_flights['FlightNum'].iloc[0]\n",
    "    origin = min_distance_flights['Origin'].iloc[0]\n",
    "    dest = min_distance_flights['Dest'].iloc[0]\n",
    "\n",
    "    same_route_flights = df[\n",
    "        (df['UniqueCarrier'] == carrier) &\n",
    "        (df['FlightNum'] == flight_num) &\n",
    "        (df['Origin'] == origin) &\n",
    "        (df['Dest'] == dest)\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nВсе рейсы {carrier}{flight_num} {origin}-{dest}:\")\n",
    "    print(same_route_flights[['Year', 'Month', 'DayofMonth', 'Distance']].sort_values(['Year', 'Month', 'DayofMonth']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siUu7vFqhHnl"
   },
   "source": [
    "**8. (0.3 балла)** Не выглядит ли подозрительным минимальное пройденное расстояние? В какие дни и на каких рейсах оно было? Какое расстояние было пройдено этими же рейсами в другие дни?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "37fOSgJDhHnm",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "07dc910d-f413-4d9b-ec45-a65034c42b68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Минимальное пройденное расстояние: 31 миль\n",
      "\n",
      "Количество рейсов с минимальным расстоянием: 6\n",
      "\n",
      "Рейсы с минимальным расстоянием:\n",
      "       Year  Month  DayofMonth  DayOfWeek UniqueCarrier  FlightNum Origin  \\\n",
      "1116   2008     12          30          2            AS         65    WRG   \n",
      "6958   2008     12          26          5            AS         65    WRG   \n",
      "17349  2008      8          18          1            AS         64    PSG   \n",
      "27534  2008      3          11          2            AS         64    PSG   \n",
      "46082  2008      8           9          6            AS         65    WRG   \n",
      "48112  2008      2          28          4            AS         64    PSG   \n",
      "\n",
      "      Dest  Distance  ActualElapsedTime  AirTime  \n",
      "1116   PSG        31               25.0     13.0  \n",
      "6958   PSG        31                NaN      NaN  \n",
      "17349  WRG        31                NaN      NaN  \n",
      "27534  WRG        31               19.0     10.0  \n",
      "46082  PSG        31               36.0      8.0  \n",
      "48112  WRG        31               28.0     15.0  \n",
      "\n",
      "Уникальные маршруты с минимальным расстоянием (2):\n",
      "\n",
      "Маршрут: AS65 WRG -> PSG\n",
      "Всего рейсов на этом маршруте: 3\n",
      "Расстояние: min=31.0, max=31.0, mean=31.0\n",
      "Примеры рейсов:\n",
      " Year  Month  DayofMonth  Distance\n",
      " 2008     12          30        31\n",
      " 2008     12          26        31\n",
      " 2008      8           9        31\n",
      "\n",
      "Маршрут: AS64 PSG -> WRG\n",
      "Всего рейсов на этом маршруте: 3\n",
      "Расстояние: min=31.0, max=31.0, mean=31.0\n",
      "Примеры рейсов:\n",
      " Year  Month  DayofMonth  Distance\n",
      " 2008      8          18        31\n",
      " 2008      3          11        31\n",
      " 2008      2          28        31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "#\n",
    "df = pd.read_csv('2008.csv')\n",
    "\n",
    "# Находим минимальное расстояние\n",
    "min_distance = df['Distance'].min()\n",
    "print(f\"Минимальное пройденное расстояние: {min_distance} миль\")\n",
    "\n",
    "# Находим все рейсы с минимальным расстоянием\n",
    "min_distance_flights = df[df['Distance'] == min_distance]\n",
    "print(f\"\\nКоличество рейсов с минимальным расстоянием: {len(min_distance_flights)}\")\n",
    "\n",
    "print(\"\\nРейсы с минимальным расстоянием:\")\n",
    "print(min_distance_flights[['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'UniqueCarrier', 'FlightNum',\n",
    "                          'Origin', 'Dest', 'Distance', 'ActualElapsedTime', 'AirTime']])\n",
    "\n",
    "unique_routes = min_distance_flights[['UniqueCarrier', 'FlightNum', 'Origin', 'Dest']].drop_duplicates()\n",
    "\n",
    "print(f\"\\nУникальные маршруты с минимальным расстоянием ({len(unique_routes)}):\")\n",
    "for _, route in unique_routes.iterrows():\n",
    "    carrier = route['UniqueCarrier']\n",
    "    flight_num = route['FlightNum']\n",
    "    origin = route['Origin']\n",
    "    dest = route['Dest']\n",
    "\n",
    "    print(f\"\\nМаршрут: {carrier}{flight_num} {origin} -> {dest}\")\n",
    "\n",
    "\n",
    "    all_route_flights = df[\n",
    "        (df['UniqueCarrier'] == carrier) &\n",
    "        (df['FlightNum'] == flight_num) &\n",
    "        (df['Origin'] == origin) &\n",
    "        (df['Dest'] == dest)\n",
    "    ]\n",
    "\n",
    "    print(f\"Всего рейсов на этом маршруте: {len(all_route_flights)}\")\n",
    "\n",
    "\n",
    "    distance_stats = all_route_flights['Distance'].describe()\n",
    "    print(f\"Расстояние: min={distance_stats['min']}, max={distance_stats['max']}, mean={distance_stats['mean']:.1f}\")\n",
    "\n",
    "   \n",
    "    print(\"Примеры рейсов:\")\n",
    "    print(all_route_flights[['Year', 'Month', 'DayofMonth', 'Distance']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52AvhGnYhHnm"
   },
   "source": [
    "**9. (0.3 балла)** Из какого аэропорта было произведено больше всего вылетов? В каком городе он находится?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "KK2gPOPEhHnm",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "31159e40-4a00-4cd2-96b9-e1f675fc64d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-5 аэропортов по количеству вылетов:\n",
      "Origin\n",
      "ATL    4134\n",
      "ORD    3550\n",
      "DFW    2793\n",
      "DEN    2383\n",
      "LAX    2082\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Аэропорт с наибольшим количеством вылетов: ATL\n",
      "Количество вылетов: 4134\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Подсчет вылетов по аэропортам\n",
    "departure_counts = df['Origin'].value_counts()\n",
    "top_airport = departure_counts.index[0]\n",
    "top_count = departure_counts.iloc[0]\n",
    "\n",
    "print(f\"Топ-5 аэропортов по количеству вылетов:\")\n",
    "print(departure_counts.head())\n",
    "print(f\"\\nАэропорт с наибольшим количеством вылетов: {top_airport}\")\n",
    "print(f\"Количество вылетов: {top_count}\")\n",
    "\n",
    "# Для определения города потребуется дополнительная информация\n",
    "# Обычно ATL - Atlanta, ORD - Chicago, DFW - Dallas/Fort Worth и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TM2UqBvqhHnm"
   },
   "source": [
    "**10. (0.3 балла)** Найдите для каждого аэропорта среднее время полета (`AirTime`) по всем вылетевшим из него рейсам. Какой аэропорт имеет наибольшее значение этого показателя?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Xli_gXRMhHnm",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "ad1dc2f8-5340-40c2-d8a3-706c9b5182bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 аэропортов по среднему времени полета:\n",
      "Origin\n",
      "SJU    205.200000\n",
      "BQN    193.954545\n",
      "PSE    191.875000\n",
      "STT    185.029412\n",
      "ANC    165.415094\n",
      "JFK    162.600515\n",
      "SEA    154.622744\n",
      "STX    153.000000\n",
      "EWR    142.087444\n",
      "ADK    142.000000\n",
      "Name: AirTime, dtype: float64\n",
      "\n",
      "Аэропорт с наибольшим средним временем полета: SJU\n",
      "Среднее время полета: 205.20 минут\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "mean_airtime_by_origin = df.groupby('Origin')['AirTime'].mean()\n",
    "\n",
    "# Сортировка по убыванию\n",
    "sorted_airtimes = mean_airtime_by_origin.sort_values(ascending=False)\n",
    "\n",
    "print(\"Топ-10 аэропортов по среднему времени полета:\")\n",
    "print(sorted_airtimes.head(10))\n",
    "\n",
    "top_airport = sorted_airtimes.index[0]\n",
    "top_airtime = sorted_airtimes.iloc[0]\n",
    "\n",
    "print(f\"\\nАэропорт с наибольшим средним временем полета: {top_airport}\")\n",
    "print(f\"Среднее время полета: {top_airtime:.2f} минут\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSTt9RuthHnm"
   },
   "source": [
    "**11. (0.5 балла)** Найдите аэропорт, у которого наибольшая доля задержанных (`DepDelay > 0`) рейсов. Исключите при этом из рассмотрения аэропорты, из которых было отправлено меньше 1000 рейсов (используйте функцию `filter` после `groupby`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x4XZfJWshHnm",
    "outputId": "f8e7a72c-1513-4aa1-d1c9-64f7a95036cd"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m departure_stats = \u001b[43mdf\u001b[49m.groupby(\u001b[33m'\u001b[39m\u001b[33mOrigin\u001b[39m\u001b[33m'\u001b[39m).agg(\n\u001b[32m      2\u001b[39m     total_flights=(\u001b[33m'\u001b[39m\u001b[33mDepDelay\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      3\u001b[39m     delayed_flights=(\u001b[33m'\u001b[39m\u001b[33mDepDelay\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m x: (x > \u001b[32m0\u001b[39m).sum())\n\u001b[32m      4\u001b[39m )\n\u001b[32m      6\u001b[39m filtered_airports = departure_stats[departure_stats[\u001b[33m'\u001b[39m\u001b[33mtotal_flights\u001b[39m\u001b[33m'\u001b[39m] >= \u001b[32m1000\u001b[39m]\n\u001b[32m      8\u001b[39m filtered_airports[\u001b[33m'\u001b[39m\u001b[33mdelay_ratio\u001b[39m\u001b[33m'\u001b[39m] = filtered_airports[\u001b[33m'\u001b[39m\u001b[33mdelayed_flights\u001b[39m\u001b[33m'\u001b[39m] / filtered_airports[\u001b[33m'\u001b[39m\u001b[33mtotal_flights\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "departure_stats = df.groupby('Origin').agg(\n",
    "    total_flights=('DepDelay', 'count'),\n",
    "    delayed_flights=('DepDelay', lambda x: (x > 0).sum())\n",
    ")\n",
    "\n",
    "filtered_airports = departure_stats[departure_stats['total_flights'] >= 1000]\n",
    "\n",
    "filtered_airports['delay_ratio'] = filtered_airports['delayed_flights'] / filtered_airports['total_flights']\n",
    "\n",
    "\n",
    "sorted_by_delay_ratio = filtered_airports.sort_values('delay_ratio', ascending=False)\n",
    "\n",
    "print(\"Топ-10 аэропортов по доле задержанных рейсов (>=1000 рейсов):\")\n",
    "print(sorted_by_delay_ratio[['total_flights', 'delayed_flights', 'delay_ratio']].head(10))\n",
    "\n",
    "top_delay_airport = sorted_by_delay_ratio.index[0]\n",
    "top_delay_ratio = sorted_by_delay_ratio['delay_ratio'].iloc[0]\n",
    "total_flights = sorted_by_delay_ratio['total_flights'].iloc[0]\n",
    "\n",
    "print(f\"\\nАэропорт с наибольшей долей задержанных рейсов: {top_delay_airport}\")\n",
    "print(f\"Доля задержанных рейсов: {top_delay_ratio:.2%}\")\n",
    "print(f\"Общее количество рейсов: {total_flights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIwiAWsZhHnm"
   },
   "source": [
    "## Линейная регрессия\n",
    "\n",
    "В этой части мы разберемся с линейной регрессией, способами её обучения и измерением качества ее прогнозов.\n",
    "\n",
    "Будем рассматривать датасет из предыдущей части задания для предсказания времени задержки отправления рейса в минутах (DepDelay). Отметим, что под задержкой подразумевается не только опоздание рейса относительно планируемого времени вылета, но и отправление до планируемого времени.\n",
    "\n",
    "### Подготовка данных\n",
    "\n",
    "**12. (0.5 балла)** Считайте выборку из файла при помощи функции pd.read_csv и ответьте на следующие вопросы:\n",
    "   - Имеются ли в данных пропущенные значения?\n",
    "   - Сколько всего пропущенных элементов в таблице \"объект-признак\"?\n",
    "   - Сколько объектов имеют хотя бы один пропуск?\n",
    "   - Сколько признаков имеют хотя бы одно пропущенное значение?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ZRY8AWohHnm",
    "outputId": "9a2d9664-3f8e-4d7a-9bab-0147d4ec7d38",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== АНАЛИЗ ПРОПУЩЕННЫХ ЗНАЧЕНИЙ ===\n",
      "\n",
      "1. Имеются ли в данных пропущенные значения? ДА\n",
      "2. Всего пропущенных элементов в таблице: 355215\n",
      "3. Количество объектов (строк) с хотя бы одним пропуском: 70000\n",
      "   Процент объектов с пропусками: 100.00%\n",
      "4. Количество признаков (столбцов) с хотя бы одним пропуском: 16\n",
      "   Процент признаков с пропусками: 55.17%\n",
      "\n",
      "=== ДЕТАЛЬНАЯ СТАТИСТИКА ===\n",
      "Общее количество объектов (строк): 70000\n",
      "Общее количество признаков (столбцов): 29\n",
      "Общее количество ячеек в таблице: 2030000\n",
      "Процент пропущенных значений от общего числа: 17.4983%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('2008.csv')\n",
    "\n",
    "print(\"=== АНАЛИЗ ПРОПУЩЕННЫХ ЗНАЧЕНИЙ ===\\n\")\n",
    "\n",
    "# 1. Имеются ли в данных пропущенные значения?\n",
    "has_missing_values = df.isnull().any().any()\n",
    "print(f\"1. Имеются ли в данных пропущенные значения? {'ДА' if has_missing_values else 'НЕТ'}\")\n",
    "\n",
    "# 2. Сколько всего пропущенных элементов в таблице \"объект-признак\"?\n",
    "total_missing = df.isnull().sum().sum()\n",
    "print(f\"2. Всего пропущенных элементов в таблице: {total_missing}\")\n",
    "\n",
    "# 3.\n",
    "objects_with_missing = df.isnull().any(axis=1).sum()\n",
    "print(f\"3. Количество объектов (строк) с хотя бы одним пропуском: {objects_with_missing}\")\n",
    "print(f\"   Процент объектов с пропусками: {objects_with_missing/len(df)*100:.2f}%\")\n",
    "\n",
    "features_with_missing = df.isnull().any(axis=0).sum()\n",
    "print(f\"4. Количество признаков (столбцов) с хотя бы одним пропуском: {features_with_missing}\")\n",
    "print(f\"   Процент признаков с пропусками: {features_with_missing/len(df.columns)*100:.2f}%\")\n",
    "\n",
    "#\n",
    "print(f\"\\n=== ДЕТАЛЬНАЯ СТАТИСТИКА ===\")\n",
    "print(f\"Общее количество объектов (строк): {len(df)}\")\n",
    "print(f\"Общее количество признаков (столбцов): {len(df.columns)}\")\n",
    "print(f\"Общее количество ячеек в таблице: {len(df) * len(df.columns)}\")\n",
    "print(f\"Процент пропущенных значений от общего числа: {total_missing/(len(df)*len(df.columns))*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Krq2ub8uhHnm"
   },
   "source": [
    "Как вы понимаете, также не имеет смысла рассматривать при решении поставленной задачи объекты с пропущенным значением целевой переменной. В связи с этим ответьте на следующие вопросы и выполните соответствующие действия:\n",
    "- Имеются ли пропущенные значения в целевой переменной?\n",
    "- Проанализируйте объекты с пропущенными значениями целевой переменной. Чем вызвано это явление? Что их объединяет? Можно ли в связи с этим, на ваш взгляд, исключить какие-то признаки из рассмотрения? Обоснуйте свою точку зрения.\n",
    "\n",
    "Исключите из выборки объекты **с пропущенным значением целевой переменной и со значением целевой переменной, равным 0**, а также при необходимости исключите признаки в соответствии с вашим ответом на последний вопрос из списка и выделите целевую переменную в отдельный вектор, исключив её из матрицы \"объект-признак\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ePybgLXhHnm",
    "outputId": "f87e1782-453a-40e6-a424-138137b43330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Пропущенных значений в целевой переменной 'DepDelay': 1399\n",
      "   Процент пропусков: 2.00%\n",
      "\n",
      "2. АНАЛИЗ ОБЪЕКТОВ С ПРОПУСКАМИ В ЦЕЛЕВОЙ ПЕРЕМЕННОЙ:\n",
      "   Всего таких объектов: 1399\n",
      "\n",
      "   Общие характеристики объектов с пропуском 'DepDelay':\n",
      "   Статус отмены рейсов:\n",
      "     Cancelled=1: 1399 рейсов\n",
      "\n",
      "   Другие пропуски в этих строках:\n",
      "     Среднее количество пропусков на строку: 13.59\n",
      "\n",
      "   Столбцы с пропусками в этих объектах:\n",
      "     DepTime: 1399 пропусков (100.0% от этих объектов)\n",
      "     ArrTime: 1399 пропусков (100.0% от этих объектов)\n",
      "     ActualElapsedTime: 1399 пропусков (100.0% от этих объектов)\n",
      "     AirTime: 1399 пропусков (100.0% от этих объектов)\n",
      "     ArrDelay: 1399 пропусков (100.0% от этих объектов)\n",
      "     DepDelay: 1399 пропусков (100.0% от этих объектов)\n",
      "     TaxiIn: 1399 пропусков (100.0% от этих объектов)\n",
      "     TaxiOut: 1399 пропусков (100.0% от этих объектов)\n",
      "     CarrierDelay: 1399 пропусков (100.0% от этих объектов)\n",
      "     WeatherDelay: 1399 пропусков (100.0% от этих объектов)\n",
      "     NASDelay: 1399 пропусков (100.0% от этих объектов)\n",
      "     SecurityDelay: 1399 пропусков (100.0% от этих объектов)\n",
      "     LateAircraftDelay: 1399 пропусков (100.0% от этих объектов)\n",
      "     TailNum: 820 пропусков (58.6% от этих объектов)\n",
      "     CRSElapsedTime: 4 пропусков (0.3% от этих объектов)\n",
      "\n",
      "   Анализ временных характеристик:\n",
      "     Пропусков DepTime: 1399 (100.0%)\n",
      "     Пропусков ArrTime: 1399 (100.0%)\n",
      "\n",
      "   Отмененные рейсы среди объектов с пропуском целевой переменной: 1399\n",
      "   Причины отмены:\n",
      "     A - Carrier (Авиакомпания): 558 рейсов\n",
      "     B - Weather (Погода): 542 рейсов\n",
      "     C - National Air System: 299 рейсов\n",
      "\n",
      "   Предлагается исключить признаки: ['Cancelled', 'CancellationCode', 'Diverted', 'CRSDepTime', 'CRSArrTime', 'CRSElapsedTime']\n",
      "\n",
      "4. ПРЕОБРАЗОВАНИЕ ДАННЫХ:\n",
      "   Исходный размер датасета: 70000 строк\n",
      "   После удаления пропусков в 'DepDelay': 68601 строк\n",
      "   После удаления 'DepDelay = 0': 63404 строк\n",
      "   После исключения 6 признаков: 23 столбцов\n",
      "\n",
      "   ФИНАЛЬНЫЕ РАЗМЕРЫ:\n",
      "   X (объект-признак): (63404, 22)\n",
      "   y (целевая переменная): (63404,)\n",
      "   Удалено всего: 6596 строк (9.4%)\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Предположим, что целевая переменная - это задержка вылета (DepDelay)\n",
    "target_column = 'DepDelay'\n",
    "\n",
    "# 1. Имеются ли пропущенные значения?\n",
    "missing_in_target = df[target_column].isnull().sum()\n",
    "print(f\"1. Пропущенных значений в целевой переменной '{target_column}': {missing_in_target}\")\n",
    "print(f\"   Процент пропусков: {missing_in_target/len(df)*100:.2f}%\")\n",
    "\n",
    "# 2. Анализ объектов с пропущенными значениями\n",
    "if missing_in_target > 0:\n",
    "    missing_target_rows = df[df[target_column].isnull()]\n",
    "    print(f\"\\n2. АНАЛИЗ ОБЪЕКТОВ С ПРОПУСКАМИ В ЦЕЛЕВОЙ ПЕРЕМЕННОЙ:\")\n",
    "    print(f\"   Всего таких объектов: {len(missing_target_rows)}\")\n",
    "\n",
    "    # Анализ общих характеристик\n",
    "    print(f\"\\n   Общие характеристики объектов с пропуском '{target_column}':\")\n",
    "\n",
    "    # Проверяем статус отмены рейсов\n",
    "    cancellation_status = missing_target_rows['Cancelled'].value_counts()\n",
    "    print(f\"   Статус отмены рейсов:\")\n",
    "    for status, count in cancellation_status.items():\n",
    "        print(f\"     Cancelled={status}: {count} рейсов\")\n",
    "\n",
    "    # Проверяем, есть ли другие пропуски в этих строках\n",
    "    other_missing = missing_target_rows.isnull().sum(axis=1)\n",
    "    print(f\"\\n   Другие пропуски в этих строках:\")\n",
    "    print(f\"     Среднее количество пропусков на строку: {other_missing.mean():.2f}\")\n",
    "\n",
    "    # Анализ конкретных столбцов с пропусками\n",
    "    print(f\"\\n   Столбцы с пропусками в этих объектах:\")\n",
    "    missing_cols_analysis = missing_target_rows.isnull().sum()\n",
    "    missing_cols_analysis = missing_cols_analysis[missing_cols_analysis > 0].sort_values(ascending=False)\n",
    "\n",
    "    for col, count in missing_cols_analysis.items():\n",
    "        percentage = (count / len(missing_target_rows)) * 100\n",
    "        print(f\"     {col}: {count} пропусков ({percentage:.1f}% от этих объектов)\")\n",
    "\n",
    "    # Анализ времени вылета и прилета\n",
    "    print(f\"\\n   Анализ временных характеристик:\")\n",
    "    dep_time_missing = missing_target_rows['DepTime'].isnull().sum()\n",
    "    arr_time_missing = missing_target_rows['ArrTime'].isnull().sum()\n",
    "    print(f\"     Пропусков DepTime: {dep_time_missing} ({dep_time_missing/len(missing_target_rows)*100:.1f}%)\")\n",
    "    print(f\"     Пропусков ArrTime: {arr_time_missing} ({arr_time_missing/len(missing_target_rows)*100:.1f}%)\")\n",
    "\n",
    "    # Проверяем отмененные рейсы\n",
    "    cancelled_with_missing_target = missing_target_rows[missing_target_rows['Cancelled'] == 1]\n",
    "    print(f\"\\n   Отмененные рейсы среди объектов с пропуском целевой переменной: {len(cancelled_with_missing_target)}\")\n",
    "\n",
    "    # Анализ причин отмены\n",
    "    if len(cancelled_with_missing_target) > 0:\n",
    "        cancellation_codes = cancelled_with_missing_target['CancellationCode'].value_counts()\n",
    "        print(f\"   Причины отмены:\")\n",
    "        for code, count in cancellation_codes.items():\n",
    "            reason = {\n",
    "                'A': 'Carrier (Авиакомпания)',\n",
    "                'B': 'Weather (Погода)',\n",
    "                'C': 'National Air System',\n",
    "                'D': 'Security (Безопасность)'\n",
    "            }.get(code, f'Unknown ({code})')\n",
    "            print(f\"     {code} - {reason}: {count} рейсов\")\n",
    "\n",
    "# # 3. ОБОСНОВАНИЕ ДЛЯ ИСКЛЮЧЕНИЯ ПРИЗНАКОВ\n",
    "# print(f\"\\n3. ОБОСНОВАНИЕ ДЛЯ ИСКЛЮЧЕНИЯ ПРИЗНАКОВ:\")\n",
    "# print(\"   На основе анализа можно сделать вывод:\")\n",
    "# print(\"   - Пропуски в целевой переменной связаны с отмененными рейсами\")\n",
    "# print(\"   - Для отмененных рейсов многие временные показатели (DepTime, ArrTime, etc.) не имеют смысла\")\n",
    "# print(\"   - Рекомендуется исключить временные признаки, которые дублируют информацию или нерелевантны\")\n",
    "\n",
    "# Признаки для исключения (обоснование в комментариях)\n",
    "columns_to_exclude = [\n",
    "    'Cancelled',        # Информация уже учтена при фильтрации\n",
    "    'CancellationCode', # Информация уже учтена при фильтрации\n",
    "    'Diverted',         # Рейсы с перенаправлением могут требовать отдельного анализа\n",
    "    # Временные признаки, которые могут быть избыточными:\n",
    "    'CRSDepTime',       # Плановое время вылета\n",
    "    'CRSArrTime',       # Плановое время прилета\n",
    "    'CRSElapsedTime',   # Плановое время в пути\n",
    "]\n",
    "\n",
    "print(f\"\\n   Предлагается исключить признаки: {columns_to_exclude}\")\n",
    "\n",
    "# 4. ПРЕОБРАЗОВАНИЕ ДАННЫХ\n",
    "print(f\"\\n4. ПРЕОБРАЗОВАНИЕ ДАННЫХ:\")\n",
    "\n",
    "# Исходный размер\n",
    "original_size = len(df)\n",
    "print(f\"   Исходный размер датасета: {original_size} строк\")\n",
    "\n",
    "# Исключаем объекты с пропущенным значением целевой переменной\n",
    "df_clean = df.dropna(subset=[target_column])\n",
    "after_missing_removal = len(df_clean)\n",
    "print(f\"   После удаления пропусков в '{target_column}': {after_missing_removal} строк\")\n",
    "\n",
    "# Исключаем объекты с целевой переменной равной 0\n",
    "df_clean = df_clean[df_clean[target_column] != 0]\n",
    "after_zero_removal = len(df_clean)\n",
    "print(f\"   После удаления '{target_column} = 0': {after_zero_removal} строк\")\n",
    "\n",
    "# Исключаем предложенные признаки\n",
    "columns_to_keep = [col for col in df_clean.columns if col not in columns_to_exclude]\n",
    "df_clean = df_clean[columns_to_keep]\n",
    "print(f\"   После исключения {len(columns_to_exclude)} признаков: {df_clean.shape[1]} столбцов\")\n",
    "\n",
    "# Выделяем целевую переменную\n",
    "X = df_clean.drop(columns=[target_column])  # Матрица \"объект-признак\"\n",
    "y = df_clean[target_column]                # Вектор целевой переменной\n",
    "\n",
    "print(f\"\\n   ФИНАЛЬНЫЕ РАЗМЕРЫ:\")\n",
    "print(f\"   X (объект-признак): {X.shape}\")\n",
    "print(f\"   y (целевая переменная): {y.shape}\")\n",
    "print(f\"   Удалено всего: {original_size - len(X)} строк ({((original_size - len(X))/original_size)*100:.1f}%)\")\n",
    "\n",
    "# # Дополнительная информация о целевой переменной\n",
    "# print(f\"\\n   СТАТИСТИКА ЦЕЛЕВОЙ ПЕРЕМЕННОЙ (после очистки):\")\n",
    "# print(f\"   Минимум: {y.min()}\")\n",
    "# print(f\"   Максимум: {y.max()}\")\n",
    "# print(f\"   Среднее: {y.mean():.2f}\")\n",
    "# print(f\"   Медиана: {y.median():.2f}\")\n",
    "# print(f\"   Стандартное отклонение: {y.std():.2f}\")\n",
    "\n",
    "# # Проверка на оставшиеся пропуски\n",
    "# remaining_missing = X.isnull().sum().sum()\n",
    "# print(f\"\\n   Оставшиеся пропуски в матрице X: {remaining_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-Z2VFVZhHnn"
   },
   "source": [
    "**13. (0.5 балла)** Обратите внимание, что признаки DepTime, CRSDepTime, ArrTime, CRSArrTime приведены в формате hhmm, в связи с чем будет не вполне корректно рассматривать их как вещественные.\n",
    "\n",
    "Преобразуйте каждый признак FeatureName из указанных в пару новых признаков FeatureName\\_Hour, FeatureName\\_Minute, разделив каждое из значений на часы и минуты. Не забудьте при этом исключить исходный признак из выборки. В случае, если значение признака отсутствует, значения двух новых признаков, его заменяющих, также должны отсутствовать.\n",
    "\n",
    "Например, признак DepTime необходимо заменить на пару признаков DepTime_Hour, DepTime_Minute. При этом, например, значение 155 исходного признака будет преобразовано в значения 1 и 55 признаков DepTime_Hour, DepTime_Minute соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5R_dGQWEhHnn",
    "outputId": "d5202be6-f332-4f94-88a6-77903d09f8ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ПРЕОБРАЗОВАНИЕ ВРЕМЕННЫХ ПРИЗНАКОВ ИЗ ФОРМАТА HHMM ===\n",
      "\n",
      "Исходные временные признаки для преобразования:\n",
      "  DepTime: примеры значений [2111.0, 1426.0, 1143.0]\n",
      "  CRSDepTime: примеры значений [2055, 1410, 1145]\n",
      "  ArrTime: примеры значений [2308.0, 1730.0, 1501.0]\n",
      "  CRSArrTime: примеры значений [2300, 1728, 1520]\n",
      "\n",
      "Преобразование признаков:\n",
      "  Обрабатывается DepTime...\n",
      "    Примеры преобразования:\n",
      "      2111 -> час: 21.0, минуты: 11.0\n",
      "      1426 -> час: 14.0, минуты: 26.0\n",
      "      1143 -> час: 11.0, минуты: 43.0\n",
      "  Обрабатывается CRSDepTime...\n",
      "    Примеры преобразования:\n",
      "      2055 -> час: 20, минуты: 55\n",
      "      1410 -> час: 14, минуты: 10\n",
      "      1145 -> час: 11, минуты: 45\n",
      "  Обрабатывается ArrTime...\n",
      "    Примеры преобразования:\n",
      "      2308 -> час: 23.0, минуты: 8.0\n",
      "      1730 -> час: 17.0, минуты: 30.0\n",
      "      1501 -> час: 15.0, минуты: 1.0\n",
      "  Обрабатывается CRSArrTime...\n",
      "    Примеры преобразования:\n",
      "      2300 -> час: 23, минуты: 0\n",
      "      1728 -> час: 17, минуты: 28\n",
      "      1520 -> час: 15, минуты: 20\n",
      "\n",
      "Удаление исходных временных признаков:\n",
      "\n",
      "=== РЕЗУЛЬТАТ ПРЕОБРАЗОВАНИЯ ===\n",
      "Общее количество столбцов после преобразования: 33\n",
      "\n",
      "Созданные новые столбцы (8):\n",
      "  DepTime_Hour: 68601 значений, 1399 пропусков\n",
      "  DepTime_Minute: 68601 значений, 1399 пропусков\n",
      "  CRSDepTime_Hour: 70000 значений, 0 пропусков\n",
      "  CRSDepTime_Minute: 70000 значений, 0 пропусков\n",
      "  ArrTime_Hour: 68444 значений, 1556 пропусков\n",
      "  ArrTime_Minute: 68444 значений, 1556 пропусков\n",
      "  CRSArrTime_Hour: 70000 значений, 0 пропусков\n",
      "  CRSArrTime_Minute: 70000 значений, 0 пропусков\n",
      "\n",
      "=== ПРОВЕРКА КОРРЕКТНОСТИ ПРЕОБРАЗОВАНИЯ ===\n",
      "Примеры преобразованных значений:\n",
      "   DepTime_Hour  DepTime_Minute  CRSDepTime_Hour  CRSDepTime_Minute  ArrTime_Hour  ArrTime_Minute  CRSArrTime_Hour  CRSArrTime_Minute\n",
      "0          21.0            11.0             20.0               55.0          23.0             8.0             23.0                0.0\n",
      "1          14.0            26.0             14.0               10.0          17.0            30.0             17.0               28.0\n",
      "2          11.0            43.0             11.0               45.0          15.0             1.0             15.0               20.0\n",
      "3          11.0            41.0             11.0               44.0          13.0            23.0             13.0               35.0\n",
      "4           8.0            15.0              8.0               20.0          12.0            43.0             13.0                0.0\n",
      "\n",
      "=== ПРОВЕРКА ОБРАБОТКИ ПРОПУСКОВ ===\n",
      "DepTime:\n",
      "  Исходные пропуски: удален\n",
      "  Пропуски в DepTime_Hour: 1399\n",
      "  Пропуски в DepTime_Minute: 1399\n",
      "  Корректность: ДА\n",
      "CRSDepTime:\n",
      "  Исходные пропуски: удален\n",
      "  Пропуски в CRSDepTime_Hour: 0\n",
      "  Пропуски в CRSDepTime_Minute: 0\n",
      "  Корректность: ДА\n",
      "ArrTime:\n",
      "  Исходные пропуски: удален\n",
      "  Пропуски в ArrTime_Hour: 1556\n",
      "  Пропуски в ArrTime_Minute: 1556\n",
      "  Корректность: ДА\n",
      "CRSArrTime:\n",
      "  Исходные пропуски: удален\n",
      "  Пропуски в CRSArrTime_Hour: 0\n",
      "  Пропуски в CRSArrTime_Minute: 0\n",
      "  Корректность: ДА\n",
      "\n",
      "=== СТАТИСТИКА ПО НОВЫМ ПРИЗНАКАМ ===\n",
      "\n",
      "Dep время:\n",
      "  Часы: min=0.0, max=24.0, mean=13.0\n",
      "  Минуты: min=0.0, max=59.0, mean=29.9\n",
      "\n",
      "CRSDep время:\n",
      "  Часы: min=0.0, max=23.0, mean=13.0\n",
      "  Минуты: min=0.0, max=59.0, mean=26.7\n",
      "\n",
      "Arr время:\n",
      "  Часы: min=0.0, max=24.0, mean=14.5\n",
      "  Минуты: min=0.0, max=59.0, mean=29.4\n",
      "\n",
      "CRSArr время:\n",
      "  Часы: min=0.0, max=24.0, mean=14.6\n",
      "  Минуты: min=0.0, max=59.0, mean=28.9\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "print(\"=== ПРЕОБРАЗОВАНИЕ ВРЕМЕННЫХ ПРИЗНАКОВ ИЗ ФОРМАТА HHMM ===\\n\")\n",
    "\n",
    "# Временные признаки для преобразования\n",
    "time_columns = ['DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime']\n",
    "\n",
    "print(\"Исходные временные признаки для преобразования:\")\n",
    "for col in time_columns:\n",
    "    if col in df.columns:\n",
    "        sample_values = df[col].dropna().head(3).tolist()\n",
    "        print(f\"  {col}: примеры значений {sample_values}\")\n",
    "    else:\n",
    "        print(f\"  {col}: отсутствует в данных\")\n",
    "\n",
    "def convert_hhmm_to_hour_minute(series):\n",
    "    \"\"\"\n",
    "    Преобразует серию из формата HHMM в две серии: часы и минуты\n",
    "    \"\"\"\n",
    "    # Создаем новые серии с NaN значениями\n",
    "    hour_series = series.copy().astype(float)\n",
    "    minute_series = series.copy().astype(float)\n",
    "\n",
    "    # Заполняем значениями только там, где нет пропусков\n",
    "    non_null_mask = series.notna()\n",
    "\n",
    "    # Преобразуем значения\n",
    "    hour_series[non_null_mask] = (series[non_null_mask] // 100).astype(int)\n",
    "    minute_series[non_null_mask] = (series[non_null_mask] % 100).astype(int)\n",
    "\n",
    "    # Для пропусков оставляем NaN\n",
    "    hour_series[~non_null_mask] = np.nan\n",
    "    minute_series[~non_null_mask] = np.nan\n",
    "\n",
    "    return hour_series, minute_series\n",
    "\n",
    "# Применяем преобразование ко всем временным признакам\n",
    "print(f\"\\nПреобразование признаков:\")\n",
    "for time_col in time_columns:\n",
    "    if time_col in df.columns:\n",
    "        print(f\"  Обрабатывается {time_col}...\")\n",
    "\n",
    "        # Преобразуем в часы и минуты\n",
    "        hour_series, minute_series = convert_hhmm_to_hour_minute(df[time_col])\n",
    "\n",
    "        # Создаем новые названия столбцов\n",
    "        hour_col = f\"{time_col}_Hour\"\n",
    "        minute_col = f\"{time_col}_Minute\"\n",
    "\n",
    "        # Добавляем новые столбцы\n",
    "        df[hour_col] = hour_series\n",
    "        df[minute_col] = minute_series\n",
    "\n",
    "        # Проверяем преобразование на примерах\n",
    "        sample_original = df[time_col].dropna().head(3)\n",
    "        if len(sample_original) > 0:\n",
    "            print(f\"    Примеры преобразования:\")\n",
    "            for orig_val in sample_original:\n",
    "                hour_val = orig_val // 100\n",
    "                minute_val = orig_val % 100\n",
    "                print(f\"      {int(orig_val)} -> час: {hour_val}, минуты: {minute_val}\")\n",
    "\n",
    "# Удаляем исходные временные признаки\n",
    "print(f\"\\nУдаление исходных временных признаков:\")\n",
    "df = df.drop(columns=time_columns)\n",
    "\n",
    "# Проверяем результат\n",
    "print(f\"\\n=== РЕЗУЛЬТАТ ПРЕОБРАЗОВАНИЯ ===\")\n",
    "print(f\"Общее количество столбцов после преобразования: {len(df.columns)}\")\n",
    "\n",
    "# Показываем новые столбцы\n",
    "new_time_columns = []\n",
    "for time_col in time_columns:\n",
    "    hour_col = f\"{time_col}_Hour\"\n",
    "    minute_col = f\"{time_col}_Minute\"\n",
    "    if hour_col in df.columns and minute_col in df.columns:\n",
    "        new_time_columns.extend([hour_col, minute_col])\n",
    "\n",
    "print(f\"\\nСозданные новые столбцы ({len(new_time_columns)}):\")\n",
    "for col in new_time_columns:\n",
    "    non_null_count = df[col].notna().sum()\n",
    "    null_count = df[col].isna().sum()\n",
    "    print(f\"  {col}: {non_null_count} значений, {null_count} пропусков\")\n",
    "\n",
    "# Проверяем корректность преобразования на нескольких примерах\n",
    "print(f\"\\n=== ПРОВЕРКА КОРРЕКТНОСТИ ПРЕОБРАЗОВАНИЯ ===\")\n",
    "check_columns = []\n",
    "for time_col in time_columns:\n",
    "    hour_col = f\"{time_col}_Hour\"\n",
    "    minute_col = f\"{time_col}_Minute\"\n",
    "    if hour_col in df.columns and minute_col in df.columns:\n",
    "        check_columns.extend([hour_col, minute_col])\n",
    "\n",
    "if check_columns:\n",
    "    # Берем несколько строк для проверки\n",
    "    sample_df = df[check_columns].dropna().head(5)\n",
    "    print(\"Примеры преобразованных значений:\")\n",
    "    print(sample_df.to_string())\n",
    "\n",
    "# Проверяем обработку пропусков\n",
    "print(f\"\\n=== ПРОВЕРКА ОБРАБОТКИ ПРОПУСКОВ ===\")\n",
    "for time_col in time_columns:\n",
    "    hour_col = f\"{time_col}_Hour\"\n",
    "    minute_col = f\"{time_col}_Minute\"\n",
    "\n",
    "    if hour_col in df.columns and minute_col in df.columns:\n",
    "        # Проверяем, что пропуски сохранились корректно\n",
    "        original_nulls = df[time_col].isna().sum() if time_col in df.columns else \"удален\"\n",
    "        hour_nulls = df[hour_col].isna().sum()\n",
    "        minute_nulls = df[minute_col].isna().sum()\n",
    "\n",
    "        print(f\"{time_col}:\")\n",
    "        print(f\"  Исходные пропуски: {original_nulls}\")\n",
    "        print(f\"  Пропуски в {hour_col}: {hour_nulls}\")\n",
    "        print(f\"  Пропуски в {minute_col}: {minute_nulls}\")\n",
    "        print(f\"  Корректность: {'ДА' if hour_nulls == minute_nulls else 'НЕТ'}\")\n",
    "\n",
    "# Статистика по новым признакам\n",
    "print(f\"\\n=== СТАТИСТИКА ПО НОВЫМ ПРИЗНАКАМ ===\")\n",
    "for time_col in time_columns:\n",
    "    hour_col = f\"{time_col}_Hour\"\n",
    "    minute_col = f\"{time_col}_Minute\"\n",
    "\n",
    "    if hour_col in df.columns and minute_col in df.columns:\n",
    "        print(f\"\\n{time_col.replace('Time', '')} время:\")\n",
    "        print(f\"  Часы: min={df[hour_col].min()}, max={df[hour_col].max()}, mean={df[hour_col].mean():.1f}\")\n",
    "        print(f\"  Минуты: min={df[minute_col].min()}, max={df[minute_col].max()}, mean={df[minute_col].mean():.1f}\")\n",
    "\n",
    "# print(f\"\\n=== ИТОГ ===\")\n",
    "# print(f\"Исходные столбцы: {time_columns}\")\n",
    "# print(f\"Удалено столбцов: {len(time_columns)}\")\n",
    "# print(f\"Добавлено столбцов: {len(new_time_columns)}\")\n",
    "# print(f\"Общее изменение: +{len(new_time_columns) - len(time_columns)} столбцов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPqi8mSehHnn"
   },
   "source": [
    "**14. (0.5 балла)** Некоторые из признаков, отличных от целевой переменной, могут оказывать чересчур значимое влияние на прогноз, поскольку по своему смыслу содержат большую долю информации о значении целевой переменной. Изучите описание датасета и исключите признаки, сильно коррелирующие с ответами. Ваш выбор признаков для исключения из выборки обоснуйте. Кроме того, исключите признаки TailNum и Year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mPC-j4RhHnn",
    "outputId": "4fa4ae5b-aaea-47c2-e101-9e9eaa01a245"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Your code here\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== АНАЛИЗ И ИСКЛЮЧЕНИЕ СИЛЬНО КОРРЕЛИРУЮЩИХ ПРИЗНАКОВ ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Целевая переменная - задержка вылета (DepDelay)\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=== АНАЛИЗ И ИСКЛЮЧЕНИЕ СИЛЬНО КОРРЕЛИРУЮЩИХ ПРИЗНАКОВ ===\\n\")\n",
    "\n",
    "# Целевая переменная - задержка вылета (DepDelay)\n",
    "target_column = 'DepDelay'\n",
    "\n",
    "# 1. Исключаем TailNum и Year как указано в задании\n",
    "print(\"1. ОБЯЗАТЕЛЬНОЕ ИСКЛЮЧЕНИЕ:\")\n",
    "print(\"   Исключаем TailNum (номер самолета) - категориальный признак с высокой кардинальностью\")\n",
    "print(\"   Исключаем Year (год) - все данные за 2008 год, нет вариативности\")\n",
    "\n",
    "columns_to_exclude = ['TailNum', 'Year']\n",
    "\n",
    "# 2. Анализ корреляции с целевой переменной\n",
    "print(f\"\\n2. АНАЛИЗ КОРРЕЛЯЦИИ С ЦЕЛЕВОЙ ПЕРЕМЕННОЙ '{target_column}':\")\n",
    "\n",
    "# Вычисляем корреляцию для числовых признаков\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "correlation_with_target = df[numeric_columns].corr()[target_column].abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Корреляция числовых признаков с целевой переменной (по убыванию модуля):\")\n",
    "for feature, corr in correlation_with_target.head(15).items():\n",
    "    if feature != target_column:\n",
    "        print(f\"   {feature}: {corr:.4f}\")\n",
    "\n",
    "# 3. Анализ смысловой корреляции\n",
    "print(f\"\\n3. СМЫСЛОВОЙ АНАЛИЗ ПРИЗНАКОВ:\")\n",
    "\n",
    "# Признаки, которые напрямую содержат информацию о задержке\n",
    "high_correlation_features = [\n",
    "    'ArrDelay',           # Задержка прилета - напрямую связана с задержкой вылета\n",
    "    'DepDelay',           # Целевая переменная (не исключаем, но учитываем)\n",
    "    'CarrierDelay',       # Задержка по вине авиакомпании - часть общей задержки\n",
    "    'WeatherDelay',       # Задержка из-за погоды - часть общей задержки\n",
    "    'NASDelay',          # Задержка национальной воздушной системы - часть общей задержки\n",
    "    'SecurityDelay',     # Задержка безопасности - часть общей задержки\n",
    "    'LateAircraftDelay', # Задержка из-за опоздания самолета - часть общей задержки\n",
    "]\n",
    "\n",
    "print(\"Признаки, напрямую содержащие информацию о задержках:\")\n",
    "for feature in high_correlation_features:\n",
    "    if feature in df.columns:\n",
    "        corr = abs(df[feature].corr(df[target_column])) if df[feature].dtype in [np.int64, np.float64] else \"N/A\"\n",
    "        print(f\"   {feature}: корреляция = {corr}\")\n",
    "\n",
    "# 4. Анализ производных временных признаков\n",
    "print(f\"\\n4. АНАЛИЗ ПРОИЗВОДНЫХ ПРИЗНАКОВ:\")\n",
    "\n",
    "# Признаки, которые являются производными от целевой переменной\n",
    "derived_features = [\n",
    "    'ActualElapsedTime',  # Фактическое время в пути\n",
    "    'CRSElapsedTime',     # Плановое время в пути\n",
    "    'AirTime',           # Время в воздухе\n",
    "]\n",
    "\n",
    "print(\"Производные временные признаки:\")\n",
    "for feature in derived_features:\n",
    "    if feature in df.columns:\n",
    "        corr = abs(df[feature].corr(df[target_column]))\n",
    "        print(f\"   {feature}: корреляция с {target_column} = {corr:.4f}\")\n",
    "\n",
    "# 5. Обоснование исключения признаков\n",
    "print(f\"\\n5. ОБОСНОВАНИЕ ИСКЛЮЧЕНИЯ ПРИЗНАКОВ:\")\n",
    "\n",
    "# Добавляем сильно коррелирующие признаки к исключаемым\n",
    "strong_correlated_to_exclude = [\n",
    "    'ArrDelay',           # Слишком сильная корреляция с целевой переменной\n",
    "    'CarrierDelay',      # Прямая составляющая задержки\n",
    "    'WeatherDelay',      # Прямая составляющая задержки\n",
    "    'NASDelay',          # Прямая составляющая задержки\n",
    "    'SecurityDelay',     # Прямая составляющая задержки\n",
    "    'LateAircraftDelay', # Прямая составляющая задержки\n",
    "]\n",
    "\n",
    "print(\"Признаки для исключения из-за сильной корреляции:\")\n",
    "for feature in strong_correlated_to_exclude:\n",
    "    if feature in df.columns:\n",
    "        print(f\"   {feature} - содержит прямую информацию о задержке\")\n",
    "\n",
    "# Также исключаем некоторые производные признаки\n",
    "additional_to_exclude = [\n",
    "    'ActualElapsedTime',  # Сильно зависит от задержки вылета\n",
    "]\n",
    "\n",
    "print(\"\\nДополнительные признаки для исключения:\")\n",
    "for feature in additional_to_exclude:\n",
    "    if feature in df.columns:\n",
    "        corr = abs(df[feature].corr(df[target_column]))\n",
    "        print(f\"   {feature} - корреляция с целевой = {corr:.4f}\")\n",
    "\n",
    "# Объединяем все исключаемые признаки\n",
    "all_columns_to_exclude = list(set(columns_to_exclude + strong_correlated_to_exclude + additional_to_exclude))\n",
    "\n",
    "# Убедимся, что не исключаем целевую переменную\n",
    "if target_column in all_columns_to_exclude:\n",
    "    all_columns_to_exclude.remove(target_column)\n",
    "\n",
    "print(f\"\\n6. ИТОГОВЫЙ СПИСОК ИСКЛЮЧАЕМЫХ ПРИЗНАКОВ ({len(all_columns_to_exclude)}):\")\n",
    "for col in sorted(all_columns_to_exclude):\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "\n",
    "# 8. Применяем исключение признаков\n",
    "print(f\"\\n8. ПРИМЕНЕНИЕ ИСКЛЮЧЕНИЯ ПРИЗНАКОВ:\")\n",
    "\n",
    "original_columns = len(df.columns)\n",
    "print(f\"   Исходное количество признаков: {original_columns}\")\n",
    "\n",
    "# Исключаем признаки\n",
    "df_clean = df.drop(columns=[col for col in all_columns_to_exclude if col in df.columns])\n",
    "\n",
    "final_columns = len(df_clean.columns)\n",
    "print(f\"   Количество признаков после исключения: {final_columns}\")\n",
    "print(f\"   Исключено признаков: {original_columns - final_columns}\")\n",
    "\n",
    "# Проверяем, что целевая переменная осталась\n",
    "if target_column in df_clean.columns:\n",
    "    print(f\"   Целевая переменная '{target_column}' сохранена\")\n",
    "\n",
    "# Показываем оставшиеся признаки\n",
    "print(f\"\\nОСТАВШИЕСЯ ПРИЗНАКИ ({len(df_clean.columns)}):\")\n",
    "for col in sorted(df_clean.columns):\n",
    "    print(f\"   {col}\")\n",
    "\n",
    "# 9. Анализ оставшихся признаков\n",
    "print(f\"\\n9. АНАЛИЗ ОСТАВШИХСЯ ПРИЗНАКОВ:\")\n",
    "\n",
    "remaining_numeric = df_clean.select_dtypes(include=[np.number]).columns\n",
    "if target_column in remaining_numeric:\n",
    "    remaining_corr = df_clean[remaining_numeric].corr()[target_column].abs().sort_values(ascending=False)\n",
    "\n",
    "    print(\"Корреляция оставшихся признаков с целевой переменной:\")\n",
    "    for feature, corr in remaining_corr.head(10).items():\n",
    "        if feature != target_column:\n",
    "            print(f\"   {feature}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "768LJrjWhHnn"
   },
   "source": [
    "**15. (1 балл)** Приведем данные к виду, пригодному для обучения линейных моделей. Для этого вещественные признаки надо отмасштабировать, а категориальные — привести к числовому виду. Также надо устранить пропуски в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PogBkIDOhHnn"
   },
   "source": [
    "В первую очередь поймем, зачем необходимо применять масштабирование. Следующие ячейки с кодом построят гистограммы для 3 вещественных признаков выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jj0cpWARhHnn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X['DepTime_Hour'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0A4siVbUhHnn"
   },
   "outputs": [],
   "source": [
    "X['TaxiIn'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c49VXelGhHno"
   },
   "outputs": [],
   "source": [
    "X['FlightNum'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9c5EgDKhHno"
   },
   "source": [
    "Какую проблему вы наблюдаете на этих графиках? Как масштабирование поможет её исправить?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "u_iWEm3QhHno"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3WfqWR0hHno"
   },
   "source": [
    "Некоторые из признаков в нашем датасете являются категориальными. Типичным подходом к работе с ними является бинарное, или [one-hot-кодирование](https://en.wikipedia.org/wiki/One-hot).\n",
    "\n",
    "Реализуйте функцию transform_data, которая принимает на вход DataFrame с признаками и выполняет следующие шаги:\n",
    "1. Замена пропущенных значений на нули для вещественных признаков и на строки 'nan' для категориальных.\n",
    "2. Масштабирование вещественных признаков с помощью [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "3. One-hot-кодирование категориальных признаков с помощью [DictVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.DictVectorizer.html) или функции [pd.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html).\n",
    "\n",
    "Метод должен возвращать преобразованный DataFrame, который должна состоять из масштабированных вещественных признаков и закодированных категориальных (исходные признаки должны быть исключены из выборки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2wh_2fcShHno"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def transform_data(data):\n",
    "    # Создаем копию данных\n",
    "    transformed_data = data.copy()\n",
    "\n",
    "    # Разделяем признаки на вещественные и категориальные\n",
    "    numeric_features = transformed_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_features = transformed_data.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "    # 1. Замена пропущенных значений\n",
    "    for feature in numeric_features:\n",
    "        transformed_data[feature].fillna(0, inplace=True)\n",
    "\n",
    "    for feature in categorical_features:\n",
    "        transformed_data[feature].fillna('nan', inplace=True)\n",
    "\n",
    "    # 2. Масштабирование вещественных признаков\n",
    "    scaler = StandardScaler()\n",
    "    scaled_numeric = scaler.fit_transform(transformed_data[numeric_features])\n",
    "    scaled_numeric_df = pd.DataFrame(scaled_numeric, columns=numeric_features, index=transformed_data.index)\n",
    "\n",
    "    # 3. One-hot-кодирование категориальных признаков\n",
    "    categorical_dummies = pd.get_dummies(transformed_data[categorical_features], prefix=categorical_features)\n",
    "\n",
    "    # Объединяем масштабированные вещественные и закодированные категориальные признаки\n",
    "    final_data = pd.concat([scaled_numeric_df, categorical_dummies], axis=1)\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFU0D0xYhHno"
   },
   "source": [
    "Примените функцию transform_data к данным. Сколько признаков получилось после преобразования?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F79FIcWchHno",
    "outputId": "592c329c-6e06-43a2-b58d-59712523cc41"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Применяем преобразование\n",
    "X_transformed = transform_data(X)\n",
    "print(f\"Количество признаков после преобразования: {X_transformed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sx0mpaVShHno"
   },
   "source": [
    "**16. (0.5 балла)** Разбейте выборку и вектор целевой переменной на обучение и контроль в отношении 70/30 (для этого можно использовать, например, функцию [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ErCxAwMghHno",
    "outputId": "02cca553-3d14-491c-a6c8-7dbc0c3495c8"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разбиваем данные на обучение и контроль\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_transformed, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Размер обучающей выборки: {X_train.shape}\")\n",
    "print(f\"Размер тестовой выборки: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7ak7oSlhHno"
   },
   "source": [
    "### Scikit-learn\n",
    "\n",
    "<img src = \"https://pp.vk.me/c4534/u35727827/93547647/x_d31c4463.jpg\">\n",
    "Теперь, когда мы привели данные к пригодному виду, попробуем решить задачу при помощи метода наименьших квадратов. Напомним, что данный метод заключается в оптимизации функционала $MSE$:\n",
    "\n",
    "$$MSE(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 \\to \\min_{w},$$\n",
    "\n",
    "где $\\{ (x_i, y_i ) \\}_{i=1}^l$ — обучающая выборка, состоящая из $l$ пар объект-ответ.\n",
    "\n",
    "Заметим, что решение данной задачи уже реализовано в модуле sklearn в виде класса [LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression).\n",
    "\n",
    "**17. (0.5 балла)** Обучите линейную регрессию на 1000 объектах из обучающей выборки и выведите значения $MSE$ и $R^2$ на этой подвыборке и контрольной выборке (итого 4 различных числа). Проинтерпретируйте полученный результат — насколько качественные прогнозы строит полученная модель? Какие проблемы наблюдаются в модели?\n",
    "\n",
    "**Подсказка**: изучите значения полученных коэффициентов $w$, сохраненных в атрибуте coef_ объекта LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "ELegRoglhHno",
    "outputId": "6fb9a8db-29f8-47f9-9ef7-02b6f7afd5d3"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Берем первые 1000 объектов для обучения\n",
    "X_train_small = X_train.iloc[:1000]\n",
    "y_train_small = y_train.iloc[:1000]\n",
    "\n",
    "# Обучаем линейную регрессию\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Предсказания\n",
    "y_train_pred = lr.predict(X_train_small)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "# Метрики на обучающей выборке\n",
    "mse_train = mean_squared_error(y_train_small, y_train_pred)\n",
    "r2_train = r2_score(y_train_small, y_train_pred)\n",
    "\n",
    "# Метрики на тестовой выборке\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Метрики на обучающей выборке (1000 объектов):\")\n",
    "print(f\"MSE: {mse_train:.2f}\")\n",
    "print(f\"R²: {r2_train:.4f}\")\n",
    "\n",
    "print(\"\\nМетрики на тестовой выборке:\")\n",
    "print(f\"MSE: {mse_test:.2f}\")\n",
    "print(f\"R²: {r2_test:.4f}\")\n",
    "\n",
    "# Анализ коэффициентов\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(lr.coef_)\n",
    "plt.title('Коэффициенты линейной регрессии')\n",
    "plt.xlabel('Номер признака')\n",
    "plt.ylabel('Значение коэффициента')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Статистика по коэффициентам\n",
    "print(f\"\\nСтатистика коэффициентов:\")\n",
    "print(f\"Минимальный коэффициент: {lr.coef_.min():.4f}\")\n",
    "print(f\"Максимальный коэффициент: {lr.coef_.max():.4f}\")\n",
    "print(f\"Среднее абсолютное значение: {np.abs(lr.coef_).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "63ANnIbohHno",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Для решения описанных вами в предыдущем пункте проблем используем L1- или L2-регуляризацию, тем самым получив Lasso и Ridge регрессии соответственно и изменив оптимизационную задачу одним из следующих образов:\n",
    "$$MSE_{L1}(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 + \\alpha ||w||_1 \\to \\min_{w},$$\n",
    "$$MSE_{L2}(X, y) = \\frac{1}{l} \\sum_{i=1}^l (<w, x_i> - y_i)^2 + \\alpha ||w||_2^2 \\to \\min_{w},$$\n",
    "\n",
    "где $\\alpha$ — коэффициент регуляризации. Один из способов его подбора заключается в переборе некоторого количества значений и оценке качества на кросс-валидации для каждого из них, после чего выбирается значение, для которого было получено наилучшее качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KA5BwtbxhHnp"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUfW-_P_hHnp"
   },
   "source": [
    "__18. (1 балл) __ Обучение линейной регрессии.\n",
    "\n",
    "\n",
    "\n",
    "Обучите линейную регрессию с $L_1$ (Lasso) и $L_2$ (Ridge) регуляризаторами (используйте параметры по умолчанию). Посмотрите, какое количество коэффициентов близко к 0 (степень близости к 0 определите сами из разумных пределов). Постройте график зависимости числа ненулевых коэффициентов от коэффицента регуляризации (перебирайте значения по логарифмической сетке от $10^{-3}$ до $10^3$). Согласуются ли результаты с вашими ожиданиями?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kNB4XRl7hHnp",
    "outputId": "4af8e67b-c0ee-4c54-a9f5-57c200ffe7db"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.linear_model import Lasso, Ridge, LassoCV, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Lasso регрессия\n",
    "lasso = Lasso(alpha=1.0)\n",
    "lasso.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Ridge регрессия\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Анализ ненулевых коэффициентов для Lasso\n",
    "lasso_non_zero = np.sum(np.abs(lasso.coef_) > 1e-6)\n",
    "ridge_non_zero = np.sum(np.abs(ridge.coef_) > 1e-6)\n",
    "\n",
    "print(f\"Ненулевых коэффициентов в Lasso: {lasso_non_zero}\")\n",
    "print(f\"Ненулевых коэффициентов в Ridge: {ridge_non_zero}\")\n",
    "\n",
    "# График зависимости числа ненулевых коэффициентов от коэффициента регуляризации для Lasso\n",
    "alphas = np.logspace(-3, 3, 50)\n",
    "non_zero_counts = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    lasso_temp = Lasso(alpha=alpha)\n",
    "    lasso_temp.fit(X_train_small, y_train_small)\n",
    "    non_zero = np.sum(np.abs(lasso_temp.coef_) > 1e-6)\n",
    "    non_zero_counts.append(non_zero)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(alphas, non_zero_counts)\n",
    "plt.title('Зависимость числа ненулевых коэффициентов от коэффициента регуляризации (Lasso)')\n",
    "plt.xlabel('Коэффициент регуляризации α')\n",
    "plt.ylabel('Число ненулевых коэффициентов')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Метрики для Ridge регрессии\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "print(f\"\\nМетрики Ridge регрессии:\")\n",
    "print(f\"RMSE: {rmse_ridge:.2f}\")\n",
    "print(f\"MAE: {mae_ridge:.2f}\")\n",
    "print(f\"R²: {r2_ridge:.4f}\")\n",
    "\n",
    "# Подбор коэффициента регуляризации для Ridge с кросс-валидацией\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=kf, scoring='neg_mean_squared_error')\n",
    "ridge_cv.fit(X_train_small, y_train_small)\n",
    "\n",
    "print(f\"\\nЛучший коэффициент регуляризации: {ridge_cv.alpha_}\")\n",
    "\n",
    "# Обучение с лучшим alpha\n",
    "ridge_best = Ridge(alpha=ridge_cv.alpha_)\n",
    "ridge_best.fit(X_train_small, y_train_small)\n",
    "\n",
    "# Метрики с подобранным коэффициентом\n",
    "y_pred_ridge_best = ridge_best.predict(X_test)\n",
    "\n",
    "# rmse_ridge_best = np.sqrt(mean_squared_error(y_test, y_pred_ridge_best))\n",
    "# mae_ridge_best = mean_absolute_error(y_test, y_pred_ridge_best)\n",
    "# r2_ridge_best = r2_score(y_test, y_pred_ridge_best)\n",
    "\n",
    "# print(f\"\\nМетрики Ridge регрессии с подобранным коэффициентом:\")\n",
    "# print(f\"RMSE: {rmse_ridge_best:.2f}\")\n",
    "# print(f\"MAE: {mae_ridge_best:.2f}\")\n",
    "# print(f\"R²: {r2_ridge_best:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZukV9pM6hHnp"
   },
   "source": [
    "Посчитайте для Ridge-регрессии следующие метрики: $RMSE$, $MAE$, $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WVKA1bjwhHnp",
    "outputId": "fe4f7a71-d46d-4343-ef7f-1d90a8a0d9a0"
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "rmse_ridge_best = np.sqrt(mean_squared_error(y_test, y_pred_ridge_best))\n",
    "mae_ridge_best = mean_absolute_error(y_test, y_pred_ridge_best)\n",
    "r2_ridge_best = r2_score(y_test, y_pred_ridge_best)\n",
    "\n",
    "print(f\"\\nМетрики Ridge регрессии с подобранным коэффициентом:\")\n",
    "print(f\"RMSE: {rmse_ridge_best:.2f}\")\n",
    "print(f\"MAE: {mae_ridge_best:.2f}\")\n",
    "print(f\"R²: {r2_ridge_best:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7E5P0FnrhHnp"
   },
   "source": [
    "Подберите на обучающей выборке для Ridge-регрессии коэффициент регуляризации (перебирайте значения по логарифмической сетке от $10^{-3}$ до $10^3$) для каждой из метрик при помощи кросс-валидации c 5 фолдами на тех же 1000 объектах. Для этого воспользуйтесь GridSearchCV и KFold из sklearn. Постройте графики зависимости фукнции потерь от коэффициента регуляризации. Посчитайте те же метрики снова. Заметно ли изменилось качество?\n",
    "\n",
    "Для выполнения данного задания вам могут понадобиться реализованные в библиотеке объекты [LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html), [RidgeCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) и [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "c6Y3Q37NhHnp",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "__19. (0.5 балла)__ Поиск объектов-выбросов\n",
    "\n",
    "\n",
    "Как известно, MSE сильно штрафует за большие ошибки на объектах-выбросах. С помощью cross_val_predict сделайте Out-of-Fold предсказания для обучающей выборки. Посчитайте ошибки и посмотрите на их распределение (plt.hist). Что вы видите?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "3UUy3eVthHnp",
    "outputId": "727e822c-b8e6-4df6-f248-a96a0f38d65d"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "oof_predictions = cross_val_predict(model, X_train_small, y_train_small, cv=5)\n",
    "\n",
    "# Ошибки предсказаний\n",
    "errors = y_train_small - oof_predictions\n",
    "\n",
    "# Распределение ошибок\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(errors, bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.title('Распределение ошибок предсказаний')\n",
    "plt.xlabel('Ошибка')\n",
    "plt.ylabel('Частота')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(np.abs(errors), bins=50, alpha=0.7, edgecolor='black')\n",
    "plt.title('Распределение абсолютных ошибок')\n",
    "plt.xlabel('Абсолютная ошибка')\n",
    "plt.ylabel('Частота')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Анализ выбросов\n",
    "print(f\"Статистика ошибок:\")\n",
    "print(f\"Средняя ошибка: {errors.mean():.2f}\")\n",
    "print(f\"Стандартное отклонение ошибок: {errors.std():.2f}\")\n",
    "print(f\"Максимальная положительная ошибка: {errors.max():.2f}\")\n",
    "print(f\"Максимальная отрицательная ошибка: {errors.min():.2f}\")\n",
    "\n",
    "# Определяем выбросы (ошибки больше 3 стандартных отклонений)\n",
    "outlier_threshold = 3 * errors.std()\n",
    "outliers = np.abs(errors) > outlier_threshold\n",
    "\n",
    "print(f\"\\nКоличество выбросов: {np.sum(outliers)}\")\n",
    "print(f\"Доля выбросов: {np.mean(outliers):.4f}\")\n",
    "\n",
    "# Анализ объектов с наибольшими ошибками\n",
    "largest_errors_idx = np.argsort(np.abs(errors))[-10:]\n",
    "print(f\"\\nНаибольшие ошибки: {errors.iloc[largest_errors_idx].values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
